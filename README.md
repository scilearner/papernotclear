# 深度学习论文

方向都没有， 看这些有什么用， 记不住了

[Think不Clear废话系列](https://github.com/scilearner/papernotclear/blob/master/old_thinknotclear.md) 大概是不再更新了， 而且又删了一些

现在是 **无聊到发疯、只放音乐系列**

| 论文名 | Bilibili 或别的 | Youtube | 序号   |
| ------------------------------------------------------------ | -------------------------------------------------------- | ------------------------------------------------------ | ----------------------------------------- | ---- | ---------------- |
| [All are Worth Word A ViT Backbone for Diffusion Models](https://www.bilibili.com/video/BV1QY4y1D7JY/)  | CVPR 2023 | | 1 |
| [StyleGAN-XL GAN重回图像生成第一宝座](https://www.bilibili.com/video/BV1Tv4y157Gw/)  | SIGGRAPH 2022 | | 2 |
| [GigaGAN: Scaling up GANs for Text-to-Image Synthesis](https://www.bilibili.com/video/BV1vm4y1k7eL/)  | CVPR 2023 | | 3 |
| [Consistency Models 超高效扩散模型diffusion只用一两步就能生成图像](https://www.bilibili.com/video/BV1gL411k76R/)  | | | 4 |
| [LERF: 3D场景中查询检索物品 利用CLIP+NeRF](https://www.bilibili.com/video/BV1ts4y1n7kT/)  | Language Embedded Radiance Fields | | 5 |
| [T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://www.bilibili.com/video/BV13c411L71U/)  | JMLR | | 6 |
| [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://www.bilibili.com/video/BV1TM411g73k/)  | | | 7 |
| [GLM General Language Model Pretraining with Autoregressive Blank Infilling](https://www.bilibili.com/video/BV1oo4y1s7d7/)  | ACL2022 | | 8 |
|   | | | 9 |
|   | | | 10 |