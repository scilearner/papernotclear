# 深度学习论文

蜻蜓点论文， paperskim,   deep learning papers. the table of content of all my videos

[B站Think不Clear](https://space.bilibili.com/17529417/video)   [Youtube(PaperThinkNotClear)](https://www.youtube.com/channel/UCwyMgDylnGQ-Wf4N00RmWJw)  

[西瓜视频](https://www.ixigua.com/home/110050360886) 但标题字数限制，我都改成中文名了， 所以， 我都没法搜索

[幻灯片 Slides on OneDrive](https://1drv.ms/u/s!AgCFFlwzHuH8jFTeW-hXFpY9jEs3?e=JqmxFI) （还有不到1个月有效期？）

百度网盘 baidu pan（附2维码，但可能并不如直接用链接方便） 链接：[https://pan.baidu.com/s/1fTQnIGhQ3hcvjlDrM4NNFA](https://pan.baidu.com/s/1fTQnIGhQ3hcvjlDrM4NNFA)
提取码：ks3c



![WeChat Image_20210723175011](pan.jpg)

| 论文名| Bilibili| Youtube| Arxiv| 博客 | 序号   |
| ------------------------------------------------------------ | -------------------------------------------------------- | ------------------------------------------------------ | ----------------------------------------- | ---- | ---------------- |
|CoMatch: Semi-supervised Learning with Contrastive Graph Regularization | | | |  | 190 |
| Event Extraction by Answering (Almost) Natural Questions | | | |  | 189 |
| You never cluster Alone | | | |  | 188 |
| Complement Objective Training | | | |  | 187 |
| Well-classified Examples are Underestimated in Classification with DNN | | | |  | 186 |
| When Does Label Smoothing Help | | | |  | 185 |
| SEED: Self-supervised Distillation For Visual Representation| | | |  | 184 |
| MixText: Hidden Space MixUp for Semi-Supervised Text Classification | | | |  | 183 |
| Nearest Neighbor Matching for Deep Clustering | | | |  | 182 |
| Conditional Self-Supervised Learning for Few-Shot Classification | | | |  | 181 |
| [Active Learning at the ImageNet Scale](https://www.bilibili.com/video/BV1kY411s7KY) | | | |  | 180 |
| [Towards Understand Generative Capability Adversarial Robust Classifier](https://www.bilibili.com/video/BV1bQ4y1i7SY) | | | |  | 179 |
| [FlexMatch Semi-Supervised Learning with Curriculum Pseudo Labeling](https://www.bilibili.com/video/BV1AR4y1b7dY) | | | |  | 178 |
| [Learning Energy-Based Models by Diffusion Recovery Likelihood](https://www.bilibili.com/video/BV11Q4y1S74k) | | | |  | 177 |
| [Self-Knowledge Distillation with Progressive Refinement of Targets](https://www.bilibili.com/video/BV1Dh411J7JZ) | | | |  | 176 |
| [AEDA: An Easier Data Augmentation Technique for Text Classification](https://www.bilibili.com/video/BV1bM4y137iA) | | | |  | 175 |
| [VAEBM: Variational Autoencoders and Energy-based Models](https://www.bilibili.com/video/BV1gg411c7Pz/) | | | |  | 174 |
| [On Separability of Self-Supervised Representations](https://www.bilibili.com/video/BV1Vf4y1A7ee/) | | | |  | 173 |
| [Revisiting Knowledge Distillation via Label Smoothing Regularization](https://www.bilibili.com/video/BV1L3411q7wg/) | | | |  | 172 |
| [Regularizing Class-wise Predictions via Self-knowledge Distillation](https://www.bilibili.com/video/BV1uh411s7qZ/) | | | |  | 171 |
| [Be Your Own Teacher: Improve CNN via Self Distillation](https://www.bilibili.com/video/BV1Xq4y1U7Vs/) | | | |  | 170 |
| Bayesian Deep Learning and a Probabilistic Perspective of Generalization | | | |  | 169 |
| Rethink Image Mixture for Unsupervised Visual Representation Learning | | | |  | 168 |
| FixMatch: Semi-Supervised Learning with Consistency and Confidence | | | |  | 167 |
| ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring  | | | |  | 166 |
| MiCE: Mixture of Contrastive Experts for Unsupervised Image Clustering | | | |  | 165 |
| Learn Representation via Information Maximizing Self-Augmented Training | | | |  | 164 |
| Supporting Clustering with Contrastive Learning | | | |  | 163 |
| Unsupervised Multi-hop Question Answering by Question Generation | | | |  | 162 |
| Perceiver: General Perception with Iterative Attention | | | |  | 161 |
| Joint EBM Training for Better Calibrated NLU Models | | | |  | 160 |
| A Unified Energy-Based Framework for Unsupervised Learning | | | |  | 159 |
| Energy-Based Models for Deep Probabilistic Regression | | | |  | 158 |
| Contrastive Learning Inverts the Data Generating Process | | | |  | 157 |
| Asymmetric Loss For Multi-Label Classification | | | |  | 156 |
| Computation-Efficient Knowledge Distillation by Uncertainty-Aware Mixup | | | |  | 155 |
| Knowledge Distillation Meets Self-Supervision | | | |  | 154 |
| Feature Projection for Improved Text Classification | | | |  | 153 |
| Improve Joint Train of Inference Net and Structure Predict EnergyNet | | | |  | 152 |
| BertGCN: Transductive Text Classification by Combining GCN and Bert | | | |  | 151 |
| The Authors Matter Understand Mitigate Implicit Bias in text classification | | | |  | 150 |
| Learning Approximate Inference Networks for Structured Prediction | | | |  | 149 |
| End-to-End Learning for Structured Prediction Energy Networks | | | |  | 148 |
| Revisiting Unsupervised Relation Extraction | | | |  | 147 |
| Sentence Meta-Embeddings for Unsupervised Semantic Textual Similarity | | | |  | 146 |
| X-Class: Text Classification with Extremely Weak Supervision | | | |  | 145 |
| Paint by Word | | | |  | 144 |
| Shape-Texture Debiased Neural Network Training | | | |  | 143 |
| Contrastive Learning through Alignment and Uniformity on the Hypersphere | | | |  | 142 |
| Deep INFOMAX representation mutual information estimation maximization | | | |  | 141 |
| SimCSE: Simple Contrastive Learning of Sentence Embeddings | | | |  | 140 |
| IMOJIE Iterative Memory-Based Joint Open Information Extraction | | | |  | 139 |
| Trash is Treasure Resisting Adversarial Examples by Adversarial Examples | | | |  | 138 |
| Enhancing Adversarial Defense by k-Winners-Take-All | | | |  | 137 |
| On Adaptive Attacks to Adversarial Example Defenses | | | |  | 136 |
| Knowledge distillation via softmax regression representation learning | | | |  | 135 |
| Revisiting Locally Supervised Learning Alternative to End-to-end Training | | | |  | 134 |
| Putting An End to End-to-End Gradient-Isolated Learning of Representations | | | |  | 133 |
| 防御defense变分自编码器 | | | |  | 132 |
| Triple Wins Accuracy Robustness Efficiency by Input-adaptive Inference | | | |  | 131 |
| Using latent space regression to analyze leverage compositionality in GANs | | | |  | 130 |
| Theoretically(没看) Principled Trade-off between Robustness and Accuracy | | | |  | 129 |
| Representation learning with contrastive predictive coding | | | |  | 128 |
| Learning Representations for Time Series Clustering | | | |  | 127 |
| Stochastic Security: Adversarial Defense Using Long-Run Dynamics of EBM | | | |  | 126 |
| Improving Adversarial Robustness via Channel-wise Activation Suppressing | | | |  | 125 |
| Likelihood Landscapes: A Unifying Principle Behind Adversarial Defenses | | | |  | 124 |
| Barlow Twins: Self-Supervised Learning via Redundancy Reduction | | | |  | 123 |
| Geometry-Aware Instance-Reweighted Adversarial Training | | | |  | 122 |
| A Closer Look at Accuracy vs Robustness | | | |  | 121 |
| Unsupervised Clustering of Seismic Signals 地震波 using autoencoders | | | |  | 120 |
| Towards the first adversarially robust neural network model on MNIST | | | |  | 119 |
| PGD对抗训练 Towards Deep Learning Models Resistant to Adversarial Attacks | | | |  | 118 |
| Denoising Diffusion Probabilistic Models | | | |  | 117 |
| Deep Unsupervised Learning using Nonequilibrium Thermodynamics | | | |  | 116 |
| Variational Inference with Normalizing Flows | | | |  | 115 |
| CutMix Regularization Strategy with Localizable Features | | | |  | 114 |
| Clustering-friendly Representation Learning Feature Decorrelate | | | |  | 113 |
| Energy-based Out-of-distribution Detection | | | |  | 112 |
| High-Performance Large-Scale Image Recognition Without Normalization | | | |  | 111 |
| Characterizing signal propagation in unnormalized ResNets | | | |  | 110 |
| Concept Learners for Few-Shot Learning | | | |  | 109 |
| Image Generation by Minimize Frechet Distance in Discriminator feature space | | | |  | 108 |
| Learning Non-Convergent Non-Persistent Short-Run MCMC to EBM | | | |  | 107 |
| Concept Whitening for Interpretable Image Recognition | | | |  | 106 |
| Loss Landscape Sightseeing with Multi-Point Optimization | | | |  | 105 |
| Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs | | | |  | 104 |
| Essentially No Barriers in Neural Network Energy Landscape | | | |  | 103 |
| Visualizing the Loss Landscape of Neural Nets | | | |  | 102 |
| Self-training for Few-shot Transfer Across Extreme Task Differences | | | |  | 101 |
| Darts: Differentiable architecture search | | | |  | 100 |
| Architecture Search Space in Neural Architecture Search(NAS) | | | |  | 99 |
| Free Lunch for Few-shot Learning: Distribution Calibration | | | |  | 98 |
| Online Deep Clustering for Unsupervised Representation Learning | | | |  | 97 |
| Coarse-to-Fine Pre-training for Named Entity Recognition | | | |  | 96 |
| Unsupervised Domain Adaptation with Variational Information Bottleneck | | | |  | 95 |
| A Unified MRC Framework for Named Entity Recognition | | | |  | 94 |
| Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness | | | | | 93 |
| Super-Convergence: Very Fast Training of NN use large LR | | | | | 92 |
| Contrastive Clustering | | | | | 91 |
| Graph Contrastive Learning with Augmentations NIPS 2020 / [Graph Contrastive Learning with Adaptive Augmentation WWW 2021 [GCC: Graph Contrastive Coding for Graph Neural Network ... KDD 2021 | [GNN and Contrastive Learning | | | | 90 |
| Contrastive Representation Distillation | | | | | 89 |
| Spectral Norm Regularization for Improving the Generalizability of NN | | | | | 88 |
| UDA: Unsupervised Data Augmentation for Consistency Training | | | | | 87 |
| Simplify the Usage of Lexicon in Chinese NER | | | | | 86 |
| Chinese NER Using Lattice LSTM | | | | | 85 |
| Uncertainty-aware Self-training for Few-shot Text Classification | | | | | 84 |
| Concept Learning with Energy-Based Models | | | |  | 83 |
| Training data-efficient image transformers distillation through attention | | | |  | 82 |
| Adversarial Training Methods for Semi-Supervised Text Classification | | | |  | 81 |
| Delta-training Semi-Supervised Text Classification with word embedding | | | |  | 80 |
| On the Anatomy of MCMC-Based Maximum Likelihood Learning of EBMs | | | |  | 79 |
| Unsupervised Deep Embedding for Clustering Analysis | | | |  | 78 |
| Relation of Relation Learning Network for Sentence Semantic Matching | | | | | 77 |
| Contextual Parameter Generation for Universal Neural Machine Translation | | | | | 76 |
| Exploring Simple Siamese Representation Learning | | | | | 75 |
| Contextual Parameter Generation for Knowledge Graph Link Prediction | | | | | 74 |
| Robustness May Be at Odds with Accuracy | | | | | 73 |
| Learning with Multiplicative Perturbations | | | | | 72 |
| When Do Curricula Work？ | | | |  | 71 |
| Self-Supervised Contrastive Learning with Adversarial Examples | | | |  | 70 |
| Supervised Contrastive Learning | | | |  | 69 |
| A Note on the Inception Score and FID | | | |  | 68 |
| Hierarchical Semantic Aggregation for Contrastive Representation Learning | | | |  | 67 |
| Syntactic and Semantic-driven Learning for Open Information Extraction | | | |  | 66 |
| Text Classification with Negative Supervision | | | |  | 65 |
| CESI Canonicalizing Open Knowledge Bases by Embeddings and Side Information | | | |  | 64 |
| CaRe: Open Knowledge Graph Embedding | | | |  | 63 |
| No MCMC for me, Amortized sampling for fast and stable training of EBMs | | | |  | 62 |
| Knowledge Graph Embedding Based Question Answering | | | |  | 61 |
| VAT Virtual Adversarial Training for regularization semi-supervised learn | | | |  | 60 |
| CNN-Generated Images Are Surprisingly Easy to Spot.. For Now | | | |  | 59 |
| Graph Agreement Models for Semi-Supervised Learning | | | |  | 58 |
| Be More with Less: Hypergraph Attention Networks for Inductive 文本分类 | | | |  | 57 |
| Text Level Graph Neural Network for Text Classification | | | |  | 56 |
| Graph Convolutional Networks for Text Classification | | | |  | 55 |
| Learning sparse neural networks through L0 regularization | | | |  | 54 |
| BigGAN: Large Scale GAN Training for High Fidelity Natural Image Synthesis | | | |  | 53 |
| On the steerability of generative adversarial networks | | | |  | 52 |
| What Makes for Good Views for Contrastive Learning | | | |  | 51 |
| Viewmaker Networks Learning Views for Unsupervised Representation Learning | | | |  | 50 |
| Auto-Encoding Variational Bayes | | | |  | 49 |
| Adversarial Examples Improve Image Recognition | | | |  | 48 |
| Stochastic Weight Averaging for Generalization | | | |  | 47 |
| There Are Many Consistent Explanations Of Unlabeled Data | | | |  | 46 |
| Interpretable Convolutional Neural Networks | | | |  | 45 |
| Understanding Black-box Predictions via Influence Functions | | | |  | 44 |
| Adversarial Examples Are Not Bugs, They Are Features | | | |  | 43 |
| You Only Propagate Once Accelerating AT via Maximal Principle | | | |  | 42 |
| Text Classification Using Label Names Only A LM self-training way | | | |  | 41 |
| 10篇softmax，CrossEntropyLoss替代方法论文合集 | ||||40|
| Cyclical Stochastic Gradient MCMC and snapshot ensemble |||   | | 39   |
| Unsupervised Feature Learning via Non-Parametric Instance Discrimination |   | |   | | 38   |
| An Image is Worth 16x16 Words Transformers for Image Recognition at Scale |   | |   | | 37   |
| Training independent subnetworks for robust prediction |   | |   | | 36   |
| Active Learning for CNNs: A Core-Set Approach |   | |   | | 35   |
| SimCLR A Simple Framework for Contrastive Learning Visual Representation |||| | 34   |
| UNITER: UNiversal Image-TExt Representation Learning ||||| 33 |
| Image Synthesis with a Single (Robust) Classifier | | | | | 32   |
| Set Transformer A Framework for Attention-based Permutation-Invariant NN | | |   | | 31   |
| Consistency Regularization in Semi-Supervised Learning |   | |   | | 30   |
| Did the model understand the question |   | |   | | 29 |
| Rethinking Feature Distribution for Loss Functions in Image Classification |   | |   | | 28   |
| Bootstrap your own latent: A new way to self supervised learning |   | |   | | 27   |
| Hybrid Discriminative-Generative Training via Contrastive Learning(EBMs) |   | |   | | 26 |
| A Multimodal Translation-Based Approach for Knowledge Graph Representation (ACL 2018) |   | |   | | 25   |
| Deep Bayesian Active Learning with Image Data (ICML 2017)  <br />The power of ensembles for active learning in image classification (CVPR 2018) |  | |   | | 24   |
| SCAN Learnrnning to Classify Images without Labels (ECCV 2020) |   | |   | | 23   |
| Unsupervised Question Answering by Cloze Translation (ACL 2019) |   | |   | | 22   |
| Phrase-Based & Neural Unsupervised Machine Translation (EMNLP 2018) |   | |   | | 21   |
| MixUp as Locally Linear Out-Of-Manifold Regularization (AAAI 2019) |   | |   | | 20 |
| Manifold Mixup: Better Representations by Interpolating Hidden States ICML2019 |   | |   | | 19   |
| Bag of Tricks for Image Classification with CNN |   | |   | | 18   |
| On Mixup Training Improved Calibration for DNN |   | |   | | 17   |
| BERT: Pre-training of Deep Bidirectional Transformers |   | |   | | 16   |
| Rationalizing Neural Predictions (EMNLP2016) |   | |   | | 15   |
| Attention is all you need, Transformer  (NIPS 2017) |   | |   | | 14   |
| Learn To Pay Attention (ICLR 2018) |   | |   | | 13   |
| A Self-Training Method for MRC with Soft Evidence Extraction(ACL 2019) |   |  |   | | 12 |
| Deep Fool(CVPR2016) 和 Deep Defense(NIPS 2018)|   |  |   | | 11   |
| R-Trans RNN Transformer Network for 中文机器阅理解(IEEE-Access) |  |  |   | | 10   |
| 一系列Energy-based models 能量模型论文摘要简介|   |  |   | | 9    |
| Implicit Generation and Modeling with EBM(NIPS 2019)    |  |  |   | | 8    |
| MixMatch A Holistic Approach to Semi-supervised Learning(NIPS 2019) |  |  |  | | 7    |
| Obfuscated Gradients Give a False Sense of Security(ICML2017 best reward) |  |  |  | | 6    |
| Explaining and Harnessing Adversarial Examples(ICLR 2015)    |  |  |   | | 5    |
| Imagenet-Trained CNNS are Biased Towards Texture(ICLR2018)   |   |  |  | | 4 |
| Momentum Contrast for Unsupervised Visual Representation Learning(CVPR2020) |   |  |  | | 3    |
| Mixup: Beyond Empirical Risk Minimization(ICLR2018)|   |  |  | | 2    |
| Your Classifier is secretely an Energy Based Model(ICLR 2019) |   |  |  | | 1（2020-08-19） |


# Paper List

## 可解释性

- Interpretable Convolutional Neural Networks
- Understanding Black-box Predictions via Influence Functions

## Semi-Supervised Learning 半监督学习

- Regularization With Stochastic Transformations and Perturbations NIPS 2016
- Temporal Ensembling ICLR 2017
- Virtual Adversarial Training ICLR 2016
- Mean teachers are better role models: weight-averaged consistency targets NIPS 2017
- Realistic Evaluation of Deep Semi-SL NIPS 2018
- Deep co-training, ECCV 2018
- There Are Many Consistent Explanations Of Unlabeled Data why you should average ICLR 2019
- MixMatch A Holistic Approach to Semi-supervised Learning (NIPS 2019)


## Softmax CrossEntropy Variants 交叉熵变种

- An Image is Worth 16x16 Words Transformers for Image Recognition at Scale
- Learn to Pay Attention (ICLR 2018)
- Large-Margin Softmax Loss for Convolutional Neural Networks ICML2016 https://arxiv.org/abs/1612.02295
- A Discriminative Feature Learning Approach for Deep Face Recognition ECCV 2016 https://link.springer.com/chapter/10.1007/978-3-319-46478-7_31
- Large Margin Deep Networks for Classification NIPS2018 https://arxiv.org/abs/1803.05598
- Rethinking Feature Distribution for Loss Functions in Image Classification CVPR 2018 http://arxiv.org/abs/1803.02988
- Max-Mahalanobis Linear Discriminant Analysis Networks http://arxiv.org/abs/1802.09308 ICML2018
- Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness ICLR 2020 https://arxiv.org/pdf/1905.10626.pdf
- Redesigning the Classification Layer by Randomizing the Class Representation Vectors ICLR2021 under review https://openreview.net/forum?id=6_FjMpi_ebO
- Rethinking Feature Discrimination and Polymerization for Large-scale Recognition NIPS 2017 Deep Learning Workshop https://arxiv.org/abs/1710.00870
- Unsupervised Feature Learning via Non-Parametric Instance-level Discrimination http://arxiv.org/abs/1805.01978 CVPR 2018
- RBF-Softmax: Learning Deep Representative Prototypes with Radial Basis Function Softmax, ECCV 2020

## Active Learning 主动学习

- Active Learning for CNNs: A Core-Set Approach
- Deep Bayesian Active Learning with Image Data (ICML 2017)
- The power of ensembles for active learning in image classification (CVPR 2018)

## 多模态

- UNITER: UNiversal Image-TExt Representation Learning
- A Multimodal Translation-Based Approach for Knowledge Graph Representation (ACL 2018)

## Transfoormer

- Attention is All you need (NIPS 2017)
- BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding

## 稳健性 Robustness

- Explaining and Harnessing Adversarial Examples (ICLR 2015)
- Deep Fool (CVPR2016)
- Deep Defense (NIPS 2018)
- Obfuscated Gradients Give a False Sense of Security (ICML2017 best reward)
- Adversarial Examples Are Not Bugs, They Are Features
- Image Synthesis with a Single (Robust) Classifier
- Adversarial Examples Improve Image Recognition
- You Only Propagate Once Accelerating AT via Maximal Principle

## QA/MRC 机器阅读理解和问答

- R-Trans RNN Transformer Network for 中文机器阅读理解 (IEEE-Access)
- A Self-Training Method for MRC with Soft Evidence Extraction (ACL 2019)
- Did the model understand the question
- Rationalizing Neural Predictions (EMNLP2016)

## 图神经网络

- Graph Agreement Models for Semi-Supervised Learning
- Be More with Less: Hypergraph Attention Networks for Inductive 文本分类
- Text Level Graph Neural Network for Text Classification
- Graph Convolutional Networks for Text Classification


## 生成模型

### GAN 生成式对抗网络

- BigGAN: Large Scale GAN Training for High Fidelity Natural Image Synthesis
- On the steerability of generative adversarial networks

### 自编码器

- Auto-Encoding Variational Bayes

### 分析

- CNN-Generated Images Are Surprisingly Easy to Spot.. For Now 

## 神经网络稀疏化

- Learning sparse neural networks through L0 regularization

## 文本分类

- Be More with Less: Hypergraph Attention Networks for Inductive 文本分类
- Text Level Graph Neural Network for Text Classification
- Graph Convolutional Networks for Text Classification

## 无监督学习 Unsupervised Learning

- Unsupervised Question Answering by Cloze Translation (ACL 2019)
- Phrase-Based & Neural Unsupervised Machine Translation (EMNLP 2018)
- SCAN Learnrnning to Classify Images without Labels (ECCV 2020)
- Text Classification Using Label Names Only A LM self-training way

### Contrastive Learning 对比学习

- Unsupervised Feature Learning via Non-Parametric Instance Discrimination
- Momentum Contrast for Unsupervised Visual Representation Learning (CVPR2020)
- SimCLR A Simple Framework for Contrastive Learning of Visual Representation
- Bootstrap your own latent: A new way to self supervised learning
- Hybrid Discriminative-Generative Training via Contrastive Learning(EBMs)
- What Makes for Good Views for Contrastive Learning
- Viewmaker Networks Learning Views for Unsupervised Representation Learning


## EBM 能量模型

- Implicit Generation and Modeling with EBM (NIPS 2019)
- Your Classifier is secretely an Energy Based Model (ICLR 2019)
- Hybrid Discriminative-Generative Training via Contrastive Learning(EBMs)

## Tricks 技巧

- Bag of Tricks for Image Classification with CNN

###  MixUp 数据融合
- Mixup: Beyond Empirical Risk Minimization (ICLR2018)
- MixUp as Locally Linear Out-Of-Manifold Regularization (AAAI 2019)
- Manifold Mixup: Better Representations by Interpolating Hidden States ICML2019
- On Mixup Training Improved Calibration

## 集成学习

- Cyclical Stochastic Gradient MCMC
- snapshot ensemble
- Training independent subnetworks for robust prediction
- Averaging Weights Leads to Wider Optima and Better Generalization [Arxiv](https://arxiv.org/abs/1803.05407)


## 其他

- Set Transformer: A Framework for Attention-based Permutation-Invariant NN
- Imagenet-Trained CNNS are Biased Towards Texture (ICLR2018)
